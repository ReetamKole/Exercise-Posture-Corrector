{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1nf2iJBNIf3v4sq_Fg-B6E3EjTDcdhVbm","authorship_tag":"ABX9TyNwZBUGP9/vRq51+D+1iOJW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hs24qfNdA_2R","executionInfo":{"status":"ok","timestamp":1725391718261,"user_tz":-330,"elapsed":18826,"user":{"displayName":"Reetam K","userId":"07276523698280098801"}},"outputId":"61c348ab-7485-4f09-a460-66e4a6f6b1bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mediapipe\n","  Downloading mediapipe-0.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n","Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n","Collecting protobuf<5,>=4.25.3 (from mediapipe)\n","  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.0-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.0)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Downloading mediapipe-0.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.0-py3-none-any.whl (32 kB)\n","Installing collected packages: protobuf, sounddevice, mediapipe\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed mediapipe-0.10.15 protobuf-4.25.4 sounddevice-0.5.0\n"]}],"source":["pip install mediapipe\n"]},{"cell_type":"code","source":["import os\n","import cv2\n","import csv\n","import mediapipe as mp\n","\n","# Initialize MediaPipe Pose\n","mp_pose = mp.solutions.pose\n","pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n","\n","# Set the directory containing the mp4 files and output CSV path\n","video_directory = '/content/drive/MyDrive/pushup dataset/Wrong sequence'\n","csv_file_path = '/content/pushup_analysis.csv'\n","\n","# Define important landmarks\n","IMPORTANT_LMS = [\n","    \"NOSE\",\n","    \"LEFT_EYE_INNER\",\n","    \"LEFT_EYE\",\n","    \"LEFT_EYE_OUTER\",\n","    \"RIGHT_EYE_INNER\",\n","    \"RIGHT_EYE\",\n","    \"RIGHT_EYE_OUTER\",\n","    \"LEFT_EAR\",\n","    \"RIGHT_EAR\",\n","    \"MOUTH_LEFT\",\n","    \"MOUTH_RIGHT\",\n","    \"LEFT_SHOULDER\",\n","    \"RIGHT_SHOULDER\",\n","    \"LEFT_ELBOW\",\n","    \"RIGHT_ELBOW\",\n","    \"LEFT_WRIST\",\n","    \"RIGHT_WRIST\",\n","    \"LEFT_PINKY\",\n","    \"RIGHT_PINKY\",\n","    \"LEFT_INDEX\",\n","    \"RIGHT_INDEX\",\n","    \"LEFT_THUMB\",\n","    \"RIGHT_THUMB\",\n","    \"LEFT_HIP\",\n","    \"RIGHT_HIP\",\n","    \"LEFT_KNEE\",\n","    \"RIGHT_KNEE\",\n","    \"LEFT_ANKLE\",\n","    \"RIGHT_ANKLE\",\n","    \"LEFT_HEEL\",\n","    \"RIGHT_HEEL\",\n","    \"LEFT_FOOT_INDEX\",\n","    \"RIGHT_FOOT_INDEX\"\n","]\n","\n","\n","# Generate column headers\n","HEADERS = [\"Filename\", \"Pushup Count\"]\n","for lm in IMPORTANT_LMS:\n","    HEADERS += [f\"{lm.lower()}_x\", f\"{lm.lower()}_y\", f\"{lm.lower()}_z\", f\"{lm.lower()}_v\"]\n","\n","# Create a new CSV file and write headers\n","with open(csv_file_path, mode='w', newline='') as csv_file:\n","    csv_writer = csv.writer(csv_file)\n","    csv_writer.writerow(HEADERS)\n","\n","def analyze_pushups(video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    pushup_count = 0\n","    # State to track pushup position\n","    in_pushup_position = False\n","    previous_shoulder_height = None\n","\n","    # Initialize list to store landmark data for the current frame\n","    landmark_data_list = []\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # Convert the frame to RGB\n","        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","        # Process the frame and detect pose landmarks\n","        results = pose.process(rgb_frame)\n","\n","        if results.pose_landmarks:\n","            # Draw landmarks on the frame\n","            mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n","\n","            # Extract shoulder landmarks\n","            left_shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n","            right_shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n","            shoulder_height = (left_shoulder.y + right_shoulder.y) / 2\n","\n","            # Simple pushup detection logic\n","            if previous_shoulder_height is not None:\n","                if shoulder_height < previous_shoulder_height and not in_pushup_position:\n","                    pushup_count += 1\n","                    in_pushup_position = True\n","                elif shoulder_height > previous_shoulder_height:\n","                    in_pushup_position = False\n","\n","            previous_shoulder_height = shoulder_height\n","\n","            # Collect landmark data for important landmarks\n","            landmarks = {lm: {'x': 0, 'y': 0, 'z': 0, 'v': 0} for lm in IMPORTANT_LMS}\n","            for landmark_name, landmark in mp_pose.PoseLandmark.__members__.items():\n","                if landmark_name in landmarks:\n","                    landmark_data = results.pose_landmarks.landmark[landmark]\n","                    landmarks[landmark_name] = {\n","                        'x': landmark_data.x,\n","                        'y': landmark_data.y,\n","                        'z': landmark_data.z,\n","                        'v': landmark_data.visibility\n","                    }\n","\n","            # Append landmark data for the current frame\n","            landmark_data_list.append(landmarks)\n","\n","        # Display the frame (optional)\n","        # cv2.imshow('Pushup Detection', frame)\n","\n","    cap.release()\n","    # cv2.destroyAllWindows()\n","\n","    # Write the collected landmark data to CSV\n","    with open(csv_file_path, mode='a', newline='') as csv_file:\n","        csv_writer = csv.writer(csv_file)\n","        for landmarks in landmark_data_list:\n","            row = [os.path.basename(video_path), pushup_count]\n","            for lm in IMPORTANT_LMS:\n","                data = landmarks[lm]\n","                row.extend([data['x'], data['y'], data['z'], data['v']])\n","            csv_writer.writerow(row)\n","\n","    return pushup_count\n","\n","# Process each video file in the directory\n","for filename in os.listdir(video_directory):\n","    if filename.endswith(\".mp4\"):\n","        video_path = os.path.join(video_directory, filename)\n","        print(f\"Processing {video_path}\")\n","        pushup_count = analyze_pushups(video_path)\n","\n","        # Write the pushup count result to the CSV file\n","        with open(csv_file_path, mode='a', newline='') as csv_file:\n","            csv_writer = csv.writer(csv_file)\n","            csv_writer.writerow([filename, pushup_count] + [''] * (len(HEADERS) - 2))  # Ensure alignment\n","\n","# Close the Pose solution\n","pose.close()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHGvs0a8JTd-","executionInfo":{"status":"ok","timestamp":1725395122172,"user_tz":-330,"elapsed":364118,"user":{"displayName":"Reetam K","userId":"07276523698280098801"}},"outputId":"67604905-f045-4205-8a7b-6aa674f4b2e8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 57.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/18.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/13.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 167.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/6.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/4.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/11.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/14.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/1.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 153.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/16.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/15.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 107.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 171.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/23.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 104.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 155.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 81.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 110.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 156.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/7.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/10.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 37.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/19.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 55.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/17.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/2.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/9.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 150.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 56.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 44.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 105.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 36.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 151.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 58.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 198.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 108.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/21.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 149.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/8.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 166.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/3.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/12.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/20.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/5.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 168.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 42.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 152.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/22.mp4\n","Processing /content/drive/MyDrive/pushup dataset/Wrong sequence/Copy of push up 46.mp4\n"]}]},{"cell_type":"code","source":["import csv\n","import os\n","\n","# Paths to the input CSV files\n","correct_pushup_file_path = '/content/correctpushup.csv'\n","incorrect_pushup_file_path = '/content/incorrectpushup.csv'\n","\n","# Path to the output combined CSV file\n","combined_csv_file_path = '/content/pushup_analysis.csv'\n","\n","# Step 1: Create the combined CSV file\n","# Check if the combined CSV file exists. If not, create it.\n","if not os.path.exists(combined_csv_file_path):\n","    with open(combined_csv_file_path, mode='w', newline='') as combined_file:\n","        pass  # Create an empty file\n","\n","# Step 2: Initialize a list to hold the combined data\n","combined_data = []\n","\n","# Step 3: Read the correct pushup CSV file and append data to combined_data\n","with open(correct_pushup_file_path, mode='r', newline='') as correct_file:\n","    csv_reader = csv.reader(correct_file)\n","    header = next(csv_reader)  # Read the header\n","    combined_data.append(header)  # Add the header to the combined data\n","    for row in csv_reader:\n","        combined_data.append(row)\n","\n","# Step 4: Read the incorrect pushup CSV file and append data to combined_data\n","with open(incorrect_pushup_file_path, mode='r', newline='') as incorrect_file:\n","    csv_reader = csv.reader(incorrect_file)\n","    next(csv_reader)  # Skip the header\n","    for row in csv_reader:\n","        combined_data.append(row)\n","\n","# Step 5: Write the combined data to the combined CSV file\n","with open(combined_csv_file_path, mode='w', newline='') as combined_file:\n","    csv_writer = csv.writer(combined_file)\n","    csv_writer.writerows(combined_data)\n","\n","print(f\"Combined CSV file has been created and saved to {combined_csv_file_path}.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QB5Fa7v0lSPK","executionInfo":{"status":"ok","timestamp":1725395449241,"user_tz":-330,"elapsed":1952,"user":{"displayName":"Reetam K","userId":"07276523698280098801"}},"outputId":"9dbf6dc7-1022-4ad2-81f3-108d23c9ea8e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Combined CSV file has been created and saved to /content/pushup_analysis.csv.\n"]}]},{"cell_type":"code","source":["import csv\n","import random\n","\n","# Path to the original CSV file\n","csv_file_path = '/content/pushup_analysis.csv'\n","train_csv_file_path = '/content/train.csv'  # Output train file\n","test_csv_file_path = '/content/test.csv'    # Output test file\n","\n","# Read all rows from the original CSV file\n","with open(csv_file_path, mode='r', newline='') as infile:\n","    csv_reader = csv.reader(infile)\n","    rows = list(csv_reader)\n","\n","# Shuffle the rows to randomize the split\n","header = rows[0]  # Extract the header\n","data_rows = rows[1:]  # Exclude the header for shuffling\n","random.shuffle(data_rows)\n","\n","# Calculate the split index\n","split_index = int(0.8 * len(data_rows))\n","\n","# Split the data into train and test sets\n","train_rows = data_rows[:split_index]\n","test_rows = data_rows[split_index:]\n","\n","# Write the train data to train.csv\n","with open(train_csv_file_path, mode='w', newline='') as train_file:\n","    csv_writer = csv.writer(train_file)\n","    csv_writer.writerow(header)  # Write the header\n","    csv_writer.writerows(train_rows)  # Write the train rows\n","\n","# Write the test data to test.csv\n","with open(test_csv_file_path, mode='w', newline='') as test_file:\n","    csv_writer = csv.writer(test_file)\n","    csv_writer.writerow(header)  # Write the header\n","    csv_writer.writerows(test_rows)  # Write the test rows\n","\n","print(f\"CSV file has been split into {train_csv_file_path} (train) and {test_csv_file_path} (test).\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2_zIP_Xeljrt","executionInfo":{"status":"ok","timestamp":1725395525770,"user_tz":-330,"elapsed":1416,"user":{"displayName":"Reetam K","userId":"07276523698280098801"}},"outputId":"6907521b-398d-4cc2-ff7c-edca2ccdcdae"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file has been split into /content/train.csv (train) and /content/test.csv (test).\n"]}]}]}